{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLUSTERS = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load color counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = np.load('counts.npy')\n",
    "identifiers = np.arange(256 * 256)\n",
    "identifiers = identifiers.reshape(256, 256)\n",
    "counts = counts[identifiers]\n",
    "\n",
    "# for color ab (in LAB color space)\n",
    "# counts[a, b] is the number it is seen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=NUM_CLUSTERS, n_init=1000)\n",
    "\n",
    "y, x = np.where(counts > 0)\n",
    "weights = counts[y, x]\n",
    "colors = np.stack([y, x], axis=1)\n",
    "\n",
    "kmeans.fit(colors, sample_weight=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = kmeans.cluster_centers_\n",
    "q = np.quantile(counts, 0.9)\n",
    "\n",
    "plt.matshow(np.clip(counts, 0, q))\n",
    "plt.xlabel('a')\n",
    "plt.ylabel('b')\n",
    "plt.scatter(centers[:, 1], centers[:, 0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a color to integer mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = np.meshgrid(np.arange(256), np.arange(256))\n",
    "colors = np.stack([y, x], axis=2)  # shape [256, 256, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = ((np.expand_dims(colors, 2) - centers)**2).sum(3)  # shape [256, 256, NUM_CLUSTERS]\n",
    "# distance[a, b, c] is a distance from color ab to cluster center c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = distance.argmin(2).astype('uint8')\n",
    "# encoder[a, b] is an integer code for color ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = []\n",
    "for i in range(NUM_CLUSTERS):\n",
    "    d = distance[:, :, i]\n",
    "    decoder.append(np.unravel_index(d.argmin(), d.shape))\n",
    "\n",
    "decoder = np.array(decoder, dtype='uint8')\n",
    "# decoder[i] is a color for code i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('encoder.npy', encoder)\n",
    "np.save('decoder.npy', decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test color quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "MIN_DIMENSION = 256\n",
    "\n",
    "\n",
    "def quantize(path, result_path):\n",
    "    \n",
    "    cap = cv2.VideoCapture(path)\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    min_dimension = min(width, height)\n",
    "    scaler = MIN_DIMENSION/min_dimension\n",
    "    new_size = (int(width * scaler), int(height * scaler))\n",
    "    \n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "    out = cv2.VideoWriter(result_path, fourcc, fps, new_size)\n",
    "\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            frame = cv2.resize(frame, new_size, interpolation=cv2.INTER_CUBIC)\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2LAB)\n",
    "            h, w, _ = frame.shape\n",
    "\n",
    "            gray = frame[:, :, 0]\n",
    "            frame = frame[:, :, 1:]\n",
    "            frame = frame.reshape(-1, 2)\n",
    "            a, b = frame[:, 0], frame[:, 1]\n",
    "\n",
    "            gray = 255 * np.ones_like(gray)\n",
    "            codes = encoder[a, b]\n",
    "            frame = decoder[codes].reshape(h, w, 2)\n",
    "            frame = np.concatenate([np.expand_dims(gray, 2), frame], axis=2)\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_LAB2RGB)            \n",
    "            out.write(frame)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantize('data/videos/v_-xDx4qvX3KQ.mp4', 'result.avi')\n",
    "# make the result video smaller by using:\n",
    "# ffmpeg -i result.avi -c:v libx264 -c:a copy result.mp4 -y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
